{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model \n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import GRU, RepeatVector\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Line 17~22 according to your requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# declare some constants\n",
    "data_dir = \"Datasets//Surveillance_Fight_Dataset//\" \n",
    "img_height , img_width = 64, 64 # dimension of each frame of videos\n",
    "seq_len = 40 # number of images pass as one sequence\n",
    "final_seq = int(seq_len/5)\n",
    "#print(\"Final Sequence Length: \", final_seq)\n",
    "classes = [\"Non-Violent\", \"Violent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# extraction of frames from videos\n",
    "#  Creating frames from videos\n",
    "def frames_extraction(video_path):\n",
    "\tframes_list = []\n",
    "     \n",
    "\tvidObj = cv2.VideoCapture(video_path)\n",
    "    # Used as counter variable \n",
    "\tcount = 1\n",
    " \n",
    "\twhile count <= seq_len: \n",
    "         \n",
    "\t\tsuccess, image = vidObj.read() \n",
    "\t\tif success:\n",
    "\t\t\timage = cv2.resize(image, (img_height, img_width))\n",
    "\t\t\timage = image/255\n",
    "\t\t\tif count%5 == 0:\n",
    "\t\t\t\tframes_list.append(image)\n",
    "\t\t\tcount += 1\n",
    "\t\telse:\n",
    "\t\t\t#print(\"Defected frame\")\n",
    "\t\t\tbreak\n",
    " \n",
    "       \n",
    "\treturn frames_list, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# data creation\n",
    "def create_data(input_dir):\n",
    "\tX = []\n",
    "\tY = []\n",
    "     \n",
    "\tclasses_list = os.listdir(input_dir)\n",
    "     \n",
    "\tfor c in classes_list:\n",
    "\t\tprint(c)\n",
    "\t\tif c in classes:\n",
    "\t\t\tif c == \"Non-Violent\":\n",
    "\t\t\t\ty = int(0)\n",
    "\t\t\t\t#print(\"*** noFight class ***\")\n",
    "\t\t\telif c == \"Violent\":\n",
    "\t\t\t\ty = int(1)\n",
    "\t\t\t\t#print(\"*** fight class ***\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint()\n",
    "\t\t\t\t#print(\"*** Other class***\")\n",
    "\t\t\tfiles_list = os.listdir(os.path.join(input_dir, c))\n",
    "\t\t\tfor f in files_list:\n",
    "\t\t\t\tframes, count = frames_extraction(os.path.join(os.path.join(input_dir, c), f))\n",
    "\t\t\t\t#print(len(frames))\n",
    "\t           \n",
    "\t\t\t\tif len(frames) == final_seq:\n",
    "\t\t\t\t\tX.append(frames)\n",
    "\t\t\t\t\tY.append(y)\n",
    "\t     \n",
    "\tX = np.asarray(X)\n",
    "\tY = np.asarray(Y)\n",
    "\treturn X, Y\n",
    "X, Y = create_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ConvLSTM based model design\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters = 64, kernel_size = (3, 3), return_sequences = True, data_format = \"channels_last\", input_shape = (final_seq, img_height, img_width, 3)))\n",
    "model.add(ConvLSTM2D(filters = 128, kernel_size = (3, 3), return_sequences = True))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(ConvLSTM2D(filters = 256, kernel_size = (3, 3), return_sequences = True))\n",
    "#model.add(Flatten())\n",
    "#model.add(RepeatVector(1))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(GRU(200))\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "#opt = keras.optimizers.SGD(lr=0.0001)\n",
    "opt = tensorflow.keras.optimizers.Adam(0.0001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[tensorflow.keras.metrics.BinaryAccuracy()])\n",
    "earlystop = EarlyStopping(patience=50)\n",
    "callbacks = [earlystop]\n",
    "print(\"[INFO]...Model is training:\")\n",
    "history = model.fit(x = X_train, y = y_train, epochs=50, batch_size = 8 , shuffle=True, validation_split=0.10, callbacks=callbacks)\n",
    "\n",
    "print(\"[INFO]...Model is saving:\")\n",
    "model.save(\"Surveillance_trained_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
